<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Hybrid Speech/non-Speech Detection</TITLE>
<META NAME="description" CONTENT="Hybrid Speech/non-Speech Detection">
<META NAME="keywords" CONTENT="PhD_Thesis">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META NAME="Generator" CONTENT="LaTeX2HTML v2002-2-1">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="PhD_Thesis.css">

<LINK REL="previous" HREF="node67.html">
<LINK REL="up" HREF="node62.html">
<LINK REL="next" HREF="node69.html">
</HEAD>

<BODY >

<DIV CLASS="navigation"><!--Navigation Panel-->
<A NAME="tex2html1299"
  HREF="node69.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="/usr/share/latex2html/icons/next.png"></A> 
<A NAME="tex2html1295"
  HREF="node62.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="/usr/share/latex2html/icons/up.png"></A> 
<A NAME="tex2html1291"
  HREF="node67.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="/usr/share/latex2html/icons/prev.png"></A> 
<A NAME="tex2html1297"
  HREF="node2.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="/usr/share/latex2html/icons/contents.png"></A>  
<BR>
<B> Next:</B> <A NAME="tex2html1300"
  HREF="node69.html">Speaker Clusters Description and</A>
<B> Up:</B> <A NAME="tex2html1296"
  HREF="node62.html">Speech/Non-Speech Algorithm</A>
<B> Previous:</B> <A NAME="tex2html1292"
  HREF="node67.html">Model-based Speech/Non-Speech Decoder</A>
 &nbsp; <B>  <A NAME="tex2html1298"
  HREF="node2.html">Contents</A></B> 
<BR>
<BR></DIV>
<!--End of Navigation Panel-->

<H2><A NAME="SECTION00813000000000000000"></A>
<A NAME="hybrid"></A>
<BR>
Hybrid Speech/non-Speech Detection
</H2>

<P>

<DIV ALIGN="CENTER"><A NAME="hybrid_figure"></A><A NAME="3991"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 4.4:</STRONG>
<I>Hybrid Speech/non-speech detector
blocks diagram</I></CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV>

<P>
The hybrid Speech/non-Speech detector introduced here is composed
of a 2 step process, as seen in figure <A HREF="#hybrid_figure">4.4</A>,
combining the energy-based detector and the model-based decoder
presented above. The output of the energy detector is used
exclusively to initialize the model-based decoder, whose output is
used as the speaker diarization speech/non-speech input.

<P>
As described above, the functioning of the energy detector depends
on setting a threshold value properly. In an exclusively
energy-based system such threshold has to be defined using a
development set as close as possible to the test set to obtain
optimum results. By using a model-based decoding as a second step
one can relax the need for a perfectly tuned threshold since the
aim now is to obtain a rough distinction between speech and
non-speech. The Energy detector is initially run with a very low
threshold pair (1e-5/1e-6). While the number of non-speech
segments found (<SPAN CLASS="MATH"><IMG
 WIDTH="34" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img269.png"
 ALT="$ N_{sil}$"></SPAN>) is smaller than 10 the threshold pair
is raised by an order of magnitude and the energy system is rerun
(the system's computational requirement's are minimal).

<P>
This is done iteratively until <!-- MATH
 $N_{sil} > 10$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="75" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img270.png"
 ALT="$ N_{sil} &gt; 10$"></SPAN>). At that point, if
<!-- MATH
 $N_{sil}> 100$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="84" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img271.png"
 ALT="$ N_{sil}&gt; 100$"></SPAN> it is considered that there are too many silence
segments and a refinement step lowers the threshold pair, using a
smaller threshold step size, until obtaining between 10 and 100
non-speech segments. The selection of the range (10 - 100) is
defined <SPAN  CLASS="textit">a grosso modo</SPAN> in order to obtain a sufficient
amount of silence frames to train the silence model in the
model-based decoder with a low percentage of speech labelled as
silence.

<P>
Such speech/non-speech segments are used to train the two models
in the model-based decoder, which performs iterative Viterbi
decodings and EM-ML training on the data until reaching likelihood
convergence.

<P>
The use of two well known speech/non-speech detection techniques
back-to-back allows for the creation of a more robust system than
using either of them alone. On one hand, on a system totally
energy-based it is found that the optimum thresholds defining the
speech and non-speech segments are different from one recording
type to another (as it depends on the room, microphones used,
distance of the people to them, etc.) and therefore they need to
be optimized using data from the same source, becoming very
dependent on it. On the other hand, in a totally cluster-based
system, there is a need for pre-labelled data in order to train
the models (or somehow generated initial models), which is also
very dependent on the type of recording. By using both systems any
kind of data can be processed on its own, without the burden of
similar data collection or annotation.

<P>
The proposed system is not parameter free. There are three main
parameters that need to be determined in order to obtain optimum
results. These are the minimum duration of the speech/non-speech
in the energy-based detector, the number of Gaussian mixtures
assigned to speech in the model-based decoder and the minimum
duration of speech and non-speech in such decoder. These are
though more robust to changes in the recording acoustics.

<DIV CLASS="navigation"><HR>
<!--Navigation Panel-->
<A NAME="tex2html1299"
  HREF="node69.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="/usr/share/latex2html/icons/next.png"></A> 
<A NAME="tex2html1295"
  HREF="node62.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="/usr/share/latex2html/icons/up.png"></A> 
<A NAME="tex2html1291"
  HREF="node67.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="/usr/share/latex2html/icons/prev.png"></A> 
<A NAME="tex2html1297"
  HREF="node2.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="/usr/share/latex2html/icons/contents.png"></A>  
<BR>
<B> Next:</B> <A NAME="tex2html1300"
  HREF="node69.html">Speaker Clusters Description and</A>
<B> Up:</B> <A NAME="tex2html1296"
  HREF="node62.html">Speech/Non-Speech Algorithm</A>
<B> Previous:</B> <A NAME="tex2html1292"
  HREF="node67.html">Model-based Speech/Non-Speech Decoder</A>
 &nbsp; <B>  <A NAME="tex2html1298"
  HREF="node2.html">Contents</A></B> </DIV>
<!--End of Navigation Panel-->
<ADDRESS>
user
2008-12-08
</ADDRESS>
</BODY>
</HTML>
